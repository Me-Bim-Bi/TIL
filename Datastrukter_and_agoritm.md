# WEEK 1 - Linj√§rs√∂kning, bin√§rs√∂kning, tidskomplexitet, insertionsort och selectionsort
## Serminatoriet
Linj√§rs√∂kning: g√•r genom alla 
Bin√§rs√∂kning
- Vi jobbar bara med heltal


A. Linj√§rs√∂kning kan vara snabbare √§n bin√§rs√∂kning vid s√∂kning i en sorterad sekvens/array med minst 300 element: Om det √§r de f√∂rsta eller andra elementer... s√• kanske. 
    Falsk. log....

B. Linj√§rs√∂kning kr√§ver att sekvensen/arrayen √§r sorterad. Falsk.
C. Om ett element som s√∂ks inte finns i sekvensen/arrayen kommer bin√§rs√∂kning alltid att vara snabbare med att inse detta. Sant.
D. Om inneh√•llet i en array √§r (indexering fr.o.m 0) 13  34  36  40  44  51  56  65   76   78   89  92 
          a) kr√§vs 3 j√§mf√∂relser f√∂r att hitta elementet 56 med bin√§rs√∂kning: 51, 76, 56 => Sant
          b) kr√§vs 8 j√§mf√∂relser f√∂r att hitta elementet 76 med linj√§rs√∂kning:  9 => Falsk
          c) kr√§vs 4 j√§mf√∂relser f√∂r att hitta elementet 34 med bin√§rs√∂kning: 51, 36, 13, 34 => Sant
          d) kr√§vs 10 j√§mf√∂relser f√∂r att inse att elementet 77 inte finns med linj√§rs√∂kning: 12 => Falsk
          e) kr√§vs 3 j√§mf√∂relser f√∂r att inse att elementet 77 inte finns med bin√§rs√∂kning: => 51, 76, 77 inte finns d√§r s√• kommer vi kolla ingen 76 => Falsk
E.  Vid bin√§rs√∂kning i en sekvens/array inneh√•llande n element och kr√§vs i v√§rsta fallet k j√§mf√∂relser. Om n blir fyra g√•nger s√• stort kommer det att kr√§vas k+4 j√§mf√∂relser: => Falsk 




Tidskomplexitet
 
Vad betyder T(n) = O(f(n))? Vilken √§r definitionen av O?
Vad betyder T(n) = ‚Ñ¶(f(n))? Vilken √§r definitionen av ‚Ñ¶?
Vad betyder T(n) = Œò(f(n))? Vilken √§r definitionen av Œò?
Vilket/vilka av alternativen nedan √§r sanna om f(n) = 3.6n2 + 45.8log2n och g(n) = 16n2 + 678 och h(n) = 54.7nlog2n + 23.8n + 79
g(n) = O(nlog2n)    Falsk
g(n) = O(n3)        Sant
h(n) = O(nlog2n)    Sant
h(n) = ‚Ñ¶(n)         Sant
f(n) = ‚Ñ¶(n2)        Sant        
f(n) = Œò(n2)        Sant
Visa att T(n) = n2 + 4n + 1 √§r O(n2) 
Visa att T(n) = nlog2n + 12n + 65 √§r ‚Ñ¶(n)
Visa att T(n) = n3 + n = Œò(n3)
Vad √§r T(n) f√∂r f√∂ljande pseudokod-avsnitt
A)                          B)                          C)
                              end = n*n             A √§r en array 
i=0                         i=0                        for i=0 to n-1
res = 1                   res = 0                     index = i
while i<n               while i<end             for k = i+1 to n
     res = res*i          res = res+i                     if A(k)<A(index)
     i=i+1                   i++                                        index = k
return res              return res                swap A[i] and A[index]


Insertionsort
Vilken √§r "principen"?
Hur sorteras f√∂ljande sekvenser? 
60 40 70 30 80 10 50 90 40
90 80 70 60 50 40 30 20 10
10 20 40 30 60 50 70 80 90 
Hur m√•nga j√§mf√∂relser utf√∂rs i ovan sekvenser vid sorteringen?
Vad inneb√§r det f√∂r ett generellt v√§rde n p√• antalet?
Vilken tidkomplexitet har insertionsort i v√§rsta fallet?
Selectionsort
Vilken √§r "principen"?
Hur sorteras f√∂ljande sekvenser? 
60 40 70 30 80 10 50 90 40
90 80 70 60 50 40 30 20 10
10 20 40 30 60 50 70 80 90 
Hur m√•nga j√§mf√∂relser utf√∂rs i ovan sekvenser vid sorteringen?
Vad inneb√§r det f√∂r ett generellt antal n?
Vilken tidskomplexitet har selectionsort i v√§rsta fallet?
Kan n√•gon av de b√•da sorteringsalgoritmerna vara b√§ttre(snabbare) √§n den andra vid sortering av array med samma inneh√•ll? Motivera

## √ñvning

Sida

av 3
ZOOM
S√∂kning, tidskomplexitet insertionsort och selectionssort
1. Vilken tidskomplexitet har linj√§rs√∂kning i v√§rsta/s√§msta fallet? => O(n)
- I b√§sta fall hittar man elementet direkt (f√∂rsta platsen) ‚Üí O(1)
- I genomsnitt m√•ste man g√• igenom h√§lften av elementen ‚Üí O(n)
- I v√§rsta fallet finns inte elementet i listan, eller ligger sist ‚Üí O(n)

2. Vilken tidskomplexitet har bin√§rs√∂kning i v√§rsta/s√§msta fallet? => =(log2n)
- B√§sta fall: Elementet finns mitt i ‚Üí O(1)
- V√§rsta fall: Elementet finns inte eller √§r i ytterkant ‚Üí O(log n)

3. Vilket krav st√§lls p√• den sekvens av element som bin√§rs√∂kningen ska genomf√∂ras p√•? Sorterad

4. Kan linj√§rs√∂kning vara snabbare √§n bin√§rs√∂kning? Motivera ditt svar? Ja.Om det element som s√∂ks √§r placerat f√∂rst.

5. Anta en sorterad array med 350 element (indexerad fr.o.m 0) och att det element som s√∂ks finns
i den tredje fj√§rdedelen av arrayen. Vilka index motsvarande startindex, slutindex samt mittindex
kommer bin√§rs√∂kning att generera f√∂r den delsekvens som motsvarar den aktuella fj√§rdedelen? 
- Step 1: 0, 349, 174
- Step 2: 0, 223, 112 (175, 349, 262) 
- Step 3: 0, 87, 43 (175, 262, 218) 

6. Om tidskomplexiteten f√∂r en algoritm √§r T(n) kvadratisk, dvs cn2
, och det vid exekvering med
1000 element tog 2 mikrosekunder. Vilket √§r d√• v√§rdet p√• ‚Äôc‚Äô? 2/1000^2 = 2 * 10^-6
7. Anta att det tar 3 ms att exekvera linj√§rs√∂kning i v√§rsta fallet i en array inneh√•llande 3000 
element.
a. Hur l√•ng tid f√∂rv√§ntas det d√• ta om antalet √∂kas till 12000?
i. ca 4 ms
ii. ca 6 ms
iii. ca 12 ms => sant
b. Om det vid en annan exekvering tog 9 ms, hur m√•nga element inneh√∂ll i s√• fall arrayen? => 9000
8. Anta att det tar 3 ms att exekvera bin√§rs√∂kning f√∂r v√§rsta fallet i en array inneh√•llande 3000
element.
a. Om det vid en annan exekvering tog 9 ms, hur m√•nga element inneh√∂ll i s√• fall arrayen? => 3000^3
b. F√∂r vilket antal element, dvs v√§rde p√• n, kommer det att ta 1 ms? => 3000^1/3 = 14
9. Uttryck n3
/5+21n2
-14n+3 i Œò-notation => n^3 => v√§xte snabbaste
10. √Ñr 2 n+1 = O(2n  => ja )? √Ñr 2 2n = O(2 n )? => nej, 2^2n √§r mycket snabbare √§n O(2^n)
11. Visa att f(n) = 12n3 + 4n2 ‚Äì 12 = O(n3
)
12. Analysera och best√§m tidkomplexiteten O(f(n)) f√∂r pseudokod-avsnitten nedan
a. result = 1
for i = 0 to 100
result = result*(i+n)
b. result = 0
for i = 2n down to 0
result = result + i
c. result = 0
for i=0 to n
for k=i to n
result = result + A[k]
A[i] = result
result = 0
d. for i=1 to n
k = i-1
temp = A[i]
while k>=0 AND temp < A[k]
k--
A[k+1] = temp
e. result = 0;
if number MOD 2 == 0
for i=0 to n
result = result + i
else
result = number*number
13. Vilken tidskomplexitet har Selectionsort i v√§rsta fallet? => O(n^2)
14. Visa hur inneh√•llet i arrayen nedan sorteras med insertionsort resp selectionsort
a)
b)
15. Anta funktionen f(n) =7n3 ‚Äì 5n2 + 20n. Nedan f√∂ljer n√•gra p√•st√•enden avseende hur funktionen
v√§xer beroende p√• n.
a. f(n) = O(n4
) Korrekt
b. f(n) = O(n2
)
c. f(n) = ‚Ñ¶(n2
) Korrekt
d. f(n) = ‚Ñ¶(n) Korrekt
e. f(n) = Œò(n3
) Korrekt
f. f(n) = Œò(n)
Vilket/vilka av dessa √§r korrekt/korrekta?
16. Vi exekvering av en algoritm uppm√§ttes f√∂ljande resultat. Vilket tidskomplexitet har algoritmen?
n Tid i ms
100 0.000002
1000 0.000022
10000 0.000222
100000 0.002205
1000000 0.022711
17. Vi exekvering av en algoritm uppm√§ttes f√∂ljande resultat. Vilket tidskomplexitet har algoritmen?
n Tid i ms
100 0.000006
1000 0.000371
10000 0.03322
100000 3.33
1000000 NA
56 31 8 96 77 13 45 31 29 56
23 45 56 40 62 66 78 63 83 89



=================
# Vecka 2

Seminarium A2
Omfattar prim√§rt tillbakablick p√• Divide-and-Conquer, Rekursion, Mergesort, Quicksort och dessutom lite mer kring partitioneringsprincip f√∂r quicksort samt Heapsort (och definition av Heap).

## Divide-and-conquer

- Vad inneb√§r denna teknik?
- Hur relaterar det till rekursion? 

## Mergesort
- Princip
- Pseudokod om merge-algoritmen √§r given
- Hur sorteras 
    - **After mergesort(), k√∂r man merge() d√§r l√•r man ihop 2 sorterad listor och sorterar den igen.**
    - 22  11  10  63  74  55  48  33
    - 22  5  11  19  55  63  74  10  48  33 7 13
- Tidskomplexitet: T(n) = n(log(n))
- Stabil? In-place? inte


## Quicksort
Princip
Pseudokod om partitioneringslagoritmen √§r given
```
Quicksort(a, start, slut)
    if (start < slut)
        pivot = partition(a, start, slut)
        Quicksort(a, start, pivot -1 )
        Quicksort(a, pivot +1, slut)
        

```



Pivot-element
Partitionering
Att best√§mma pivot-element -> olika alternativ
Visa hur f√∂ljden sorteras om pivot elementet alltid √§r det sista och partitioneringen utf√∂rs enligt kurslitteraturen
48  63  19  26  88  89  12  53  9  4  66  83  92  45 
11  22  33  44  55  66  77  88  99 
Tidskomplexitet: nlog(n) men kanske bara...O(n)
Stabil? In-place? kan vara stabil om man inte valjer pivot felt.

## Heap, Heapsort, 
(max)-Heap (anta att indexeringen i arrayen b√§rjar p√• 0)
Struktur och regel
Utg√• fr√•n en array med inneh√•llet 35 56 47 25 98 20 34 42 15 och omvandla detta till en max-heap genom att arbeta "bottom-up".
g√• fr√•n v√§nster till h√∂ger och fylla p√• tr√§det. Sedan g√∂r man med "bottom-up"

Ta d√§refter bort det st√∂rsta v√§rdet.
P√• vilket index finns 56?
P√• vilket index finns 15?
P√• vilket index finns f√∂r√§ldern till 20?
P√• vilka index finns v√§nster barn respektive h√∂ger till 42?
P√• vilka index finns f√∂r√§ldern, v√§nster barn respektve h√∂ger barn till elementet p√• index k?

## Heapsort
Princip 
Visa hur f√∂ljden 73  48  19  26  88  39  12  53  19  4  66  83  92  28 sorteras med heapsort
Tidskomplexitet: n.log(n) f√∂r att bygga tr√§det
Stabil? Nej. Inplace? 
d-heap: mer √§n 2 barn p√• tr√§det. dn+1 dn+2 => barn. (4-1)/d => r√§kna f√∂r√§ldra

==========================
# Vecka 3
## Seminarium A3
Omfattar prim√§rt Countingsort, Radixsort samt tillbakablick/repetition Heapsort och eventuellt viss repetition av inneh√•llet i Del A.

### 1. Countingsort
Princip (olika bearbetningssteg): A √§r den listan/arrayen som beh√∂ver sortera. Skapa 2 listor/array C och D. Max[A] = k. C[0->k+q]. C[A[i]] = C[A[j]+1]. B[C[A[j]]] = A[j]
Vi g√∂r n√•got exempel: 
```
A:  5  4  0  5  5  4  2  0  1

Steg1:
A:  5  4  0  5  5  4  2  0  1
C:  0  0  0  0  0  0

Steg 2:
A:          5  4  0  5  5  4  2  0  1
B:
C:          2  1  1  0  2  3
Index C:    0  1  2  3  4  5 


Steg3:
A:          5  4  0  5  5  4  2  0  1
B: 
C:          2  3  4  4  6  9
Index C:    0  1  2  3  4  5 


Steg 4:
A:          5  4  0  5  5  4  2  0  1
B:          0  0  1  2  4  4  5  5  5
C:          0  2  3  4  4  6    (Minska med 1 f√∂rst innan man stoppar det p√• array B)
Index C:    0  1  2  3  4  5 
```

Tidskomplexitet **O(k+n) (k = max)**
Stabil? Ja. **(om man sorterar det bak ifr√•n bara).**
In-place? Nej, f√∂r att det kr√§vs extra minne.

### 2. Bucketsort: 
O(n) i sitt medel/f√∂rv√§ntade fall. Delar upp datan i "hinkar" sedan anv√§nder elementen som nycklar/index. 
Stabil om den inre sorteringsalgoritmen √§r stabil. 
Inte in-place, extra minne baseras p√• k.
V√§rstafalls O(n^2)

### 3. Radixsort
Princip och ‚Äùkrav‚Äù p√• nycklarna som ska sorteras: datan √§r heltal. Sorterar varje siffa f√∂r sig: hundra tal, tio tal, en tal... G√•r fr√•n minst signifikanta siffran till den mest signifikanta siffran. Oftast anv√§nds buckets eller countingsort som subrutin. 
Hur kan countingsort utnyttjas? sorterar varje siffa f√∂r sig
Vi g√∂r n√•got exempel
Tidskomplexitet: O(d(n+k))
Stabil? Ja. In-place? Nej.
B√§ttra val √§n CountingSort om v√§rdena skalar kvadratiskt gentemot antalet element.
```
A:          02  14  07  10
Index C:    0  1  2  3  4  5  6  7 
C:          1  0  1  0  1  0  0  1

A:          02  14  07  10
Index C:    0  1  2  3  4  5  6  7 
C:          1  1  2  2  3  3  3  4
B:          10  02  14  07


A:          02  14  07  10
Index C:    0  1  
C:          2  2
B:          02  07  10  14

A:          02  14  07  10
Index C:    0  1  
C:          2  4
B:          02  07  10  14
```

### 4. Heapsort
Repeterar kort. N√§r man byggar en max-heap kollar man ner-upp och bytter plats om de beh√∂vs.
Vi g√∂r eventuellt n√•got exempel
Radixsort vs Heapsort
d(k+n)  s n(logn)
d=4, k=10, n=500 => Radixsort:T(n)= 2040
                    Heapsort: T(n) = 500(log(500)) = 500.9 = 4500


### 5. Vilken/Vilka √§r stabila? 
Insertionsort, mergesort, bucketsort, counting sort, radixsort.
Om n=500 och nycklarna √§r heltal inom [0..9999] vilken av algoritmerna √§r d√• teoretiskt ‚Äùsnabbast‚Äù?

6 element eller mindre => insertionsort √§r snabbare √§n dem andra.
Hybridsorteringen v√§ljer Mergesort n√§r elementer mer √§n 6. N√§r kommer elementer mindre √§n 6 => k√∂r man insertionsort. Sedan samlar man med Merge.

===============
## Seminarium A3: Till√§gg (repetition Del A)
1. Best√§m Œò-notationer f√∂r funktionerna
```
g(n) = 34.5n2 + 16nlogn + 12 => O(n2)
h(n) = 53.7 => O(1)
f(n) = 4.5 + 8.7logn => O(log n)
```
f(n) = 4.5 + 8.7logn + 5n=> 5n v√§xer snabbare √§n 8.7log n => O(n)


2. Visa att g(n) = 2n2 + 4n + 10 = Œò(n2) 
```
n >= 4: 4n <= n^2
        10 < n^2 
        2n^2 + 4n + 10 < 4n^2

2n^2 + 4n + 10 >= 1*n^2 
=> g(n) = 2n2 + 4n + 10 = Œò(n2)
```

3. Vid exekvering (v√§rsta fallet) av en algoritm med T(n) =  Œü(n3) tog det 0.5 ms n√§r n=2000. Hur l√•ng tid kommer det d√• att ta om n √∂kas till 4000? => 4ms

4. Vid exekvering (v√§rsta fallet) av en algoritm med T(n) =  Œü(log2n) tog det 1 mikrosekund n√§r n=100. Vid en annan exekvering (v√§rsta fallet) av samma algoritm tog det 4 mikrosekunder. Hur var n vid detta tillf√§lle? => 100^4

5. Anta sekvensen 10 15 22 28 34 45 50 58 60 73 79 85 93 och s√∂kning av elementet 66 utf√∂rs enligt algoritmen f√∂r bin√§rs√∂kning. Hur m√•nga kontrollen/j√§mf√∂relser g√∂rs mot elementet i sekvensen under denna s√∂kning och vilka element kommer att j√§mf√∂ras med 66? 
```
steg 1: 50 => h√∂ger
steg 2: 73 => v√§nster
steg 3: 58 => h√∂ger
steg 4: 60 => inte finns 66.
=> 4 j√§mf√∂ras och det √§r 60 som j√§mf√∂ras med 66.
```

6. Skriv pseudokod f√∂r rekursiv bin√§rs√∂kning:
```
BinarySearch(A, x)
low = 0
high = length[A]-1
while low <= high
    mid = (low + high)/2
    if x == A[mid]
        return mid
    if x < A[mid]
        high = mid - 1
    else if x > A[mid]
        low = mid + 1
return -1
```

7. Vilket √§r v√§rsta fallet f√∂r linj√§rs√∂kning och vilken tidskomplexitet g√§ller f√∂r detta fall? O(n) n√§r den som vi s√∂ker ligger i sista plats

8. Visa hur sekvensen 60  20  30  90 10  70 bearbetas om sortering utf√∂rs enligt algoritmen 
```
insertionsort: 
60  20  30  90  10  70
20  60  30  90  10  70
20  30  60  90  10  70
20  30  60  90  10  70
10  20  30  60  90  70
10  20  30  60  70  90
```

```
selectionsort: 
10  20  30  90  60  70
10  20  30  90  60  70
10  20  30  90  60  70
10  20  30  60  90  70
10  20  30  60  70  90
```

9. Visa hur sekvensen 60  20  30  90 10  70 40 bearbetas om sortering utf√∂rs enligt algoritmen
```
mergesort
60  20  30  90 10  70  40
60  20  30           |        90  10  70  40

60   |    20  30     |      90  10  |    70  40
60   |   20  30      |    10  90    |  40  70
20  30  60           |       10  40  70  90 
10  20  30  40  60  70  90
```

```
quicksort (pivot sista elementet och partitionering enligt Lomutos)
60  20  30  90  10  70  40
20  30  10  40  60  90  70
10  20  30  40  60  70  90
```
```
heapsort
90  60  70  20  10  30  40
40  60  70  20  10  30  90
70  60  40  20  10  30  90
30  60  40  20  10  70  90
60  30  40  20  10  70  90
10  30  40  20  60  70  90
40  30  10  20  60  70  90
20  30  10  40  60  70  90
30  20  10  40  60  70  90
10  20  30  40  60  70  90
```
10. Vilken √§r tidskomplexiteten O(f(n)) i b√§sta, genomsnittliga och v√§rsta fallet f√∂r quicksort, motivera b√§sta och v√§rsta fallet? V√§rsta fallet O(n^2), d√•lig pivot. B√§sta, genomsnittliga: O(nlogn)

11. Skriv pseudokod f√∂r heapsort givet algoritmen heapify(A, fromIndex, endIndex) som hanterar att placeras elementet p√• fromIndex p√• r√§tt plats s√• att inneh√•llet i arrayen A fr.o.m fromIndex motsvarar max-heapar, d√§r f√∂ruts√§ttningen √§r att elementen fr.om fromIndex +1 redan √§r max-heapar.
```
Heapsort(A)
    for i = Length(A)/2 to 1
        Heapify(A, i, Length(A))
    for i = Length(A) to 1
        Swap(A[1], A[i])
        Heapify(A, 1, i-1)
        
Heapify(A, i, n)
    max = i
    leftchild = 2 * i
    rightchild = 2 * i + 1

    if (leftchild <= n) and (A[leftchild] > A[max])
        max = leftchild
    if (rightchild <= n) and (A[rightchild] > A[max])
        max = rightchild

    if (max != i)
        Swap(A[i], A[max])
        Heapify(A, max, n)
```

=============================
# Vecka 4
## Seminarium B1
- Omfattar prim√§rt  L√§nkade listor samt Stack och K√∂.

### 1. L√§nkade listor

- Ett altenativ till arrayer f√∂r att lagra data. Data-objekt (noder) l√§nkas ihop ist√§llet f√∂r att ligga fi f√∂ljd i minnet.

‚úÖ 1. L√§nkade listor
üî∏ L√§nkalternativ:
Enkell√§nkning: Varje nod har en pekare till n√§sta nod.
Dubbell√§nkning: Varje nod har tv√• pekare ‚Äì en till n√§sta nod och en till f√∂reg√•ende.

üî∏ Klasstyp f√∂r att representera list-element:
plaintext
Copy
Edit
class Node:
    data        // det som ska lagras
    next        // pekare till n√§sta list-element

    constructor(data, next):
        this.data = data
        this.next = next
üî∏ Uppbyggnad:
Start-element: Pekare till det f√∂rsta elementet i listan (vanligtvis kallad head)

Slut-element: Det sista elementet vars next √§r null

Cirkul√§r lista: Det sista elementets next pekar tillbaka p√• det f√∂rsta elementet (head), vilket skapar en sluten cirkel

‚úÖ Pseudo-kod f√∂r enkell√§nkad lista
1. L√§gg till ett element f√∂rst i listan
plaintext
Copy
Edit
function insertFirst(head, data):
    newNode = Node(data, head)
    return newNode
Tidskomplexitet: O(1)

2. Best√§m antalet element i listan
plaintext
Copy
Edit
function countElements(head):
    count = 0
    current = head
    while current != null:
        count = count + 1
        current = current.next
    return count
Tidskomplexitet: O(n)

3. L√§gg till ett element p√• en viss position
plaintext
Copy
Edit
function insertAt(head, position, data):
    if position == 0:
        return insertFirst(head, data)

    current = head
    index = 0
    while current != null and index < position - 1:
        current = current.next
        index = index + 1

    if current == null:
        error("Position out of bounds")

    newNode = Node(data, current.next)
    current.next = newNode
    return head
Tidskomplexitet: O(n)

4. Ta bort ett element fr√•n listan givet positionen
plaintext
Copy
Edit
function removeAt(head, position):
    if head == null:
        error("List is empty")

    if position == 0:
        return head.next

    current = head
    index = 0
    while current != null and index < position - 1:
        current = current.next
        index = index + 1

    if current == null or current.next == null:
        error("Position out of bounds")

    current.next = current.next.next
    return head
Tidskomplexitet: O(n)



### 2. Stack 

Operationer
#### 2.1. Alternativ p√• intern datastruktur: 

En stack kan implementeras med:

Array (statisk storlek) ‚Äì snabb tillg√•ng men begr√§nsad kapacitet.

Dynamisk array (t.ex. vector i C++) ‚Äì flexibel storlek.

L√§nkad lista ‚Äì dynamisk, effektiv f√∂r minnesanv√§ndning.


#### 2.2. Tidskomplexitet f√∂r operationerna
üî∏ Tidskomplexitet f√∂r operationerna (generellt):

Operation	Tidskomplexitet
push(x)	O(1)
pop()	O(1)
peek() eller top()	O(1)
isEmpty()	O(1)

#### 2.3. 
Anta att du har tillg√•ng till ADT:n Stack och att f√∂ljande operationer utf√∂rs p√• en fr√•n b√∂rjan tom stack 

push(V), push(X), push(R), push(Z)
output result of peek() => Z
push(H)
output result of peek() => H
pop(), pop()
output result of peek() => R
pop()
output result of peek() => X

Vilken utskriften erh√•lls av ovan pseudokod om output result of resulterar i utskrift?

#### 2.4. Anv√§nd ADT:n Stack f√∂r att v√§nda om inneh√•llet i en array givet arrayen och dess kapacitet. Skriv bearbetningen i pseudokod.

- Antag:

    - arr √§r en array av storlek n

    - stack √§r en tom stack
```
function reverseArray(arr, n):
    stack = Stack()

    // Push all elements to stack
    for i = 0 to n - 1:
        stack.push(arr[i])

    // Pop elements back into array
    for i = 0 to n - 1:
        arr[i] = stack.pop()
```


### 3.K√∂

- Operationer
üî∏ ADT-operationer:

Operation	Beskrivning
enqueue(x)	L√§gger till ett element l√§ngst bak i k√∂n
dequeue()	Tar bort och returnerar elementet l√§ngst fram
peek() / front()	Returnerar det f√∂rsta elementet utan att ta bort det
isEmpty()	Returnerar true om k√∂n √§r tom

#### 3.1 Alternativ p√• intern datastruktur
- Array (cirkul√§r array) ‚Äì snabba operationer, kr√§ver sp√•rning av front och rear.

- Dynamisk array (t.ex. vector) ‚Äì flexibel storlek, men kr√§ver skiftning vid dequeue().

- L√§nkad lista ‚Äì enkel hantering av dynamisk storlek, O(1) f√∂r b√•da operationerna
#### 3.2 Tidskomplexitet f√∂r operationerna
‚úÖ Tidskomplexitet (f√∂r en korrekt implementerad k√∂):

Operation	Tidskomplexitet
enqueue(x)	O(1)
dequeue()	O(1)
peek()	O(1)
isEmpty()	O(1)
(Om man anv√§nder vector utan optimering, kan dequeue() bli O(n) pga skiftning.)
#### 3.3. Anta att ADT:n K√∂ (Queue) implementerats genom anv√§ndande av en array med kapaciteten 6 (indexeringen b√∂rjar p√• 0). Alla operationer som utf√∂rs p√• k√∂n tar konstant tid.
Om f√∂ljande operationer utf√∂rs i den ordning de √§r angivna:

enqueue(A), enqueue(B), enqueue(C), enqueue(D), 
dequeue(), dequeue(), dequeue(),
enqueue(E), enqueue(F), 
dequeue(), dequeue(), 
enqueue(G), enqueue(H) 


Vilket √§r inneh√•llet i arrayen efter det att alla operationerna √§r genomf√∂rda?

üì¶ Start: [ _ _ _ _ _ _ ] (kapacitet 6)
Vi antar en cirkul√§r k√∂ d√§r front och rear flyttas och wrappar runt vid behov.


Steg	Operation	Front	Rear	Inneh√•ll i array (index 0‚Äì5)
1	enqueue(A)	0	0	[A _ _ _ _ _]
2	enqueue(B)	0	1	[A B _ _ _ _]
3	enqueue(C)	0	2	[A B C _ _ _]
4	enqueue(D)	0	3	[A B C D _ _]
5	dequeue()	1	3	[A B C D _ _] (A tas bort, ignoreras)
6	dequeue()	2	3	[A B C D _ _] (B tas bort)
7	dequeue()	3	3	[A B C D _ _] (C tas bort)
8	enqueue(E)	3	4	[A B C D E _]
9	enqueue(F)	3	5	[A B C D E F]
10	dequeue()	4	5	[A B C D E F] (D tas bort)
11	dequeue()	5	5	[A B C D E F] (E tas bort)
12	enqueue(G)	5	0	[G B C D E F] (rear wrappar till 0)
13	enqueue(H)	5	1	[G H C D E F] (rear till index 1)
‚ùó Observera att de borttagna v√§rdena (t.ex. A, B, C...) tekniskt finns kvar i arrayen, men anses inte l√§ngre vara en del av k√∂n eftersom front har flyttats.
‚úÖ Slutligt inneh√•ll i arrayen (positioner 0‚Äì5):
plaintext
Copy
Edit
[G, H, C, D, E, F]  
Men det aktuella inneh√•llet i k√∂n, i r√§tt ordning, √§r:

plaintext
Copy
Edit
F, G, H
(Med front p√• index 5 och rear p√• index 1 ‚Äì cirkul√§r hantering.)

#### 3.4. Skriv pseudokod f√∂r alla operationerna som ing√•r i ADT:n Queue d√§r du ska anv√§nda ADT:n Vector som intern datastruktur. Vectorn (vars positioner b√∂rjar p√• 0) har f√∂ljande operationer
addAt(elem, pos) - l√§gger till elem p√• positionen pos
size() - ger antalet element i listan
remove(pos) - tar bort elementet p√• positionen pos 
find(elem) - returnerar den position som elem finns p√•, men om elem inte finns returneras 



Antag att vi anv√§nder en ADT Vector med:

addAt(elem, pos)

remove(pos)

size()

find(elem)
```
Klass: Queue
plaintext
Copy
Edit
class Queue:
    vector = new Vector()

    function enqueue(elem):
        vector.addAt(elem, vector.size())   // l√§gg till sist

    function dequeue():
        if isEmpty():
            error("Queue is empty")
        vector.remove(0)                    // ta bort f√∂rst

    function peek():
        if isEmpty():
            error("Queue is empty")
        return vector[0]

    function isEmpty():
        return vector.size() == 0
```